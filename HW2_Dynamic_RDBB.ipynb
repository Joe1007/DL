{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized DynamicCNN + RDBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 檢查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 定義動態卷積模塊\n",
    "class DynamicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DynamicConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # 動態權重生成網絡\n",
    "        self.weight_gen = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels * out_channels * kernel_size * kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channels * out_channels * kernel_size * kernel_size, out_channels * in_channels * kernel_size * kernel_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, _, _ = x.size()\n",
    "        weights = self.weight_gen(x.mean([2, 3])).view(batch_size, self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        weights = weights.view(batch_size * self.out_channels, self.in_channels, self.kernel_size, self.kernel_size)\n",
    "        \n",
    "        # 需要調整輸入的形狀以匹配新的卷積核\n",
    "        x = x.view(1, batch_size * self.in_channels, x.size(2), x.size(3))\n",
    "        output = F.conv2d(x, weights, stride=self.stride, padding=self.padding, groups=batch_size)\n",
    "        \n",
    "        # 調整輸出形狀以恢復原始的batch size\n",
    "        output = output.view(batch_size, self.out_channels, output.size(2), output.size(3))\n",
    "        return output\n",
    "\n",
    "# 定義RRDB模塊\n",
    "class RRDB(nn.Module):\n",
    "    def __init__(self, in_channels, growth_channels):\n",
    "        super(RRDB, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, growth_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(growth_channels, growth_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(growth_channels, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.conv3(out)\n",
    "        return out + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定義CustomCNN_DynamicConv2d_RRDB模型\n",
    "class CustomCNN_DynamicConv2d_RRDB(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN_DynamicConv2d_RRDB, self).__init__()\n",
    "        self.dynamic_conv = DynamicConv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.rrdb1 = RRDB(64, 32)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(128 * 32 * 32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.dynamic_conv(x)))\n",
    "        x = self.rrdb1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 定義數據集類\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        self.img_labels = [line.strip().split() for line in lines]\n",
    "        self.transform = transform\n",
    "        self.labels = [int(line.split()[1]) for line in lines]\n",
    "        self.classes = list(set(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.img_labels[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = int(label)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 定義數據轉換，包含數據增強\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 創建數據集和數據加載器\n",
    "train_dataset = ImageDataset(file_path='train.txt', transform=transform)\n",
    "val_dataset = ImageDataset(file_path='val.txt', transform=transform)\n",
    "test_dataset = ImageDataset(file_path='test.txt', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 創建模型和其他訓練參數\n",
    "model = CustomCNN_DynamicConv2d_RRDB(num_classes=len(train_dataset.classes))\n",
    "checkpoint_path = \"checkpoint_cnn_rrdb1.pth\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 保存模型狀態的函數\n",
    "def save_checkpoint(epoch, model, optimizer, loss, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, path)\n",
    "\n",
    "# 加載模型狀態的函數\n",
    "def load_checkpoint(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return start_epoch, loss\n",
    "\n",
    "# 訓練模型的函數\n",
    "def train_model(num_epochs, start_epoch=0):\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(torch.float32)\n",
    "            labels = labels.to(torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # 調整學習率\n",
    "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "        # 保存模型狀態\n",
    "        save_checkpoint(epoch + 1, model, optimizer, running_loss / len(train_loader), checkpoint_path)\n",
    "\n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(torch.float32)\n",
    "                labels = labels.to(torch.int64)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# 檢查是否有保存的狀態，並加載\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, _ = load_checkpoint(checkpoint_path)\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "# 評估模型\n",
    "def evaluate_model(loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(torch.float32)\n",
    "            labels = labels.to(torch.int64)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=[str(cls) for cls in train_dataset.classes]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "train_model(25, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3822\n",
      "Precision: 0.3706\n",
      "Recall: 0.3822\n",
      "F1 Score: 0.3672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.44      0.38         9\n",
      "           1       0.38      0.67      0.48         9\n",
      "           2       0.18      0.22      0.20         9\n",
      "           3       0.67      0.44      0.53         9\n",
      "           4       0.33      0.44      0.38         9\n",
      "           5       0.50      0.56      0.53         9\n",
      "           6       0.33      0.22      0.27         9\n",
      "           7       0.20      0.22      0.21         9\n",
      "           8       0.18      0.22      0.20         9\n",
      "           9       0.50      0.11      0.18         9\n",
      "          10       0.33      0.33      0.33         9\n",
      "          11       0.20      0.11      0.14         9\n",
      "          12       0.71      0.56      0.62         9\n",
      "          13       0.20      0.22      0.21         9\n",
      "          14       0.36      0.44      0.40         9\n",
      "          15       0.25      0.33      0.29         9\n",
      "          16       0.14      0.11      0.12         9\n",
      "          17       0.50      0.33      0.40         9\n",
      "          18       0.27      0.33      0.30         9\n",
      "          19       0.64      0.78      0.70         9\n",
      "          20       0.56      0.56      0.56         9\n",
      "          21       0.00      0.00      0.00         9\n",
      "          22       0.43      0.33      0.38         9\n",
      "          23       0.20      0.11      0.14         9\n",
      "          24       0.27      0.33      0.30         9\n",
      "          25       0.44      0.44      0.44         9\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.14      0.11      0.12         9\n",
      "          28       0.29      0.22      0.25         9\n",
      "          29       0.30      0.33      0.32         9\n",
      "          30       0.18      0.22      0.20         9\n",
      "          31       0.33      0.33      0.33         9\n",
      "          32       0.40      0.22      0.29         9\n",
      "          33       0.43      0.67      0.52         9\n",
      "          34       0.67      0.67      0.67         9\n",
      "          35       0.50      0.44      0.47         9\n",
      "          36       0.22      0.22      0.22         9\n",
      "          37       0.56      0.56      0.56         9\n",
      "          38       0.20      0.11      0.14         9\n",
      "          39       0.00      0.00      0.00         9\n",
      "          40       0.58      0.78      0.67         9\n",
      "          41       0.18      0.22      0.20         9\n",
      "          42       0.36      0.44      0.40         9\n",
      "          43       0.50      0.56      0.53         9\n",
      "          44       0.70      0.78      0.74         9\n",
      "          45       0.50      0.78      0.61         9\n",
      "          46       0.62      0.89      0.73         9\n",
      "          47       0.50      0.44      0.47         9\n",
      "          48       0.75      0.67      0.71         9\n",
      "          49       0.50      0.56      0.53         9\n",
      "\n",
      "    accuracy                           0.38       450\n",
      "   macro avg       0.37      0.38      0.37       450\n",
      "weighted avg       0.37      0.38      0.37       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 推論模型\n",
    "evaluate_model(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLHW2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
